[paths]

;; location where the interface can write temporary data, such as optional
;;  persistent data structures.  subdirectories may be created.
temp_space = /usr/local/scratch

;; this is the root directory under which archived pipelines and data
;;  will be stored.  it will be created if it does not exist, but
;;  write permissions must exist.  this is only for those pipelines archived
;;  to temp space.  all other pipelines are archived/compressed in place.
pipeline_archive_root = /usr/local/scratch/ergatis/archival

;; directory from which workflows will execute.  
workflow_run_dir = /usr/local/scratch/workflow

;;Log4j property file that controls debugging
workflow_log4j = /opt/workflow/log4j.properties

;; Workflow Engine install that will be used.  this directory should contain
;;  the 'RunWorkflow' and 'KillWorkflow' executables.  ergatis also sets any
;;  environmental variables needed by Workflow Engine from the value here.
workflow_root = /opt/workflow

;; global id repository is the directory containing the necessary file
;;  structure for Id::Generator to pull unique pipeline IDs.  You should
;;  take care before changing this, it could cause pipeline ID conflicts.
;; if you're setting up a install for the first time you need only to create
;;  this directory and, inside it, create an empty file named 'valid_id_repository'
;;  see the module's documentation for more information.
global_id_repository = /opt/ergatis/global_id_repository

;; this area is used to save pipeline templates that are reusable across all projects.
;;  each project has its own project_saved_templates directory, specified within
;;  that project's project.conf file.  here you should just make sure this directory 
;;  exists so users can save templates within it.
global_saved_templates = /opt/ergatis/global_saved_templates

;; as you create a pipeline the interface creates temporary backups here.  It
;;  is only after you click 'run' or 'save' that the backup is instantiated
;;  into a project area.  this directory will be created when it is first needed,
;;  though the parent should already exist.
pipeline_build_area = /tmp/pipelines_building

;; the location to the installed ergatis components and scripts is usually set using the
;;  ERGATIS_DIR variable in each project.config file.  there are times, though, when
;;  the interface needs to pull non-project specific info (such as documentation links
;;  clicked outside of a project area).  this setting allows you to specify which code
;;  area should be used when the scope of a project can't be resolved.
default_ergatis_dir = /opt/ergatis

;; the project creation page has a text box allowing the user to enter the path to the
;;  project root to be created.  for many users there will be a common prefix that all
;;  project root paths will share.  this can be entered below and the form field will
;;  be pre-populated with this value.  if you leave it blank the user will be prompted
;;  to enter the full path.
default_project_root = /usr/local/projects

;; when a new project is created a default config file is needed.  it is displayed to
;;  the user and can then be customized.
default_project_conf = /opt/ergatis/docs/project.config.example

[workflow_settings]

;; the cost of executing each pipeline, at a minimum, is holding an instance of the
;;  JRE open in memory while the pipeline runs.  even if the jobs within the pipeline are
;;  mostly distributed the local workflow instance still has to stay open and poll for
;;  job status.  setting this varaible allows you to submit the actual parent pipeline as
;;  a job to prevent one machine from running all of them.  you should set this to one
;;  if you have pipelines that run a lot of steps locally or run a large number of pipelines
;;  at once.
submit_pipelines_as_jobs = 0

;; when submitting a pipeline as a job, it is suggested to setup a different queue than
;;  you submit jobs to.  This will eliminate a gridlock case where pipelines are waiting
;;  for free slots which will not become available. 
pipeline_submission_queue = 

;; also when submitting pipelines, which project code should be used with qsub
;;  to submit the pipeline process.  This is configured separately for jobs in 
;;  the project.config file.
pipeline_submission_project = 

;; this is the amount of time the workflow engine will wait before doing incremental
;;  writes of the XML to disk.  by default it writes upon every state change, but since
;;  writing to disk can take a while on large files, leaving this off (0) can cause
;;  delays.  if four sequential commands finish within 2 seconds, for example, there's
;;  no reason to write the XML after each command finishes.
;;
;;  value in minutes, requires workflow version 3 or higher.  0 to turn off.
marshal_interval = 1

;; initial heap size allocated for the JVM. This is the amount of memory 
;;  allocated when the JVM starts up reserved for creating objects. As more objects are 
;;  created, the JVM increases the amount of memory up to the maximum heap specified. If 
;;  the maximum heap size is exceeded, the JVM will throw an exception and quit.
init_heap = 100m

;; maximum heap size allocated for the JVM. This is the maximum amount of memory allocated 
;;  for the for creating objects. The JVM stats out by allocating the initial heap, as 
;;  more objects are created, the JVM increases the amount of memory up to the maximum 
;;  heap specified. If the maximum heap size is exceeded, the JVM will throw an exception 
;;  and quit.
max_heap = 1024m

;; OPTIONAL
;; If a domain is provided the email notifications input will attempt to guess where emails 
;; should be sent by creating an email address using the user logged in and the email domain
;; supplier here:
;;
;; <USER LOGGED IN>@<EMAIL DOMAIN>
email_domain = som.umaryland.edu

[display_settings]

;; when viewing the pipeline list for a project, this limits the number that are displayed
;;  before the interface paginates them.  it also controls how many are shown per page.
pipelines_per_page = 30

;; the pipeline lists on the index page are cached and only updated every 
;;  N minutes.
pipeline_list_cache_time = 60

;; if the pipeline's last update/mod time is within N hours it will be included
;;  in the 'active' list on the index page.
active_pipeline_age = 24

;; amount of time, in days, after which pipelines will not appear on the home page lists,
;;  regardless of their state.  this is based on the ctime of the pipeline.xml file.
max_pipeline_age = 30

;; allows the display of project quota information on several pages.  this
;;  current implementation is JCVI-specific.
enable_quota_lookup = 0

;; if set to 1, the interface will display which codebase is currently in
;;  use by the project when appropriate.
display_codebase = 1

;; the interface uses animations in some place, such as expanding/contracting content
;;  containers.  this really drags on some machines, and can be turned off here.
builder_animations = 0


[grid]

;; should work be submitted to a grid?  for most installations this will probably be set to 1,
;;  in which case the settings below need to be defined.  if you want to run everything locally,
;;  (i.e. if you're testing the ErgatisVM) this should be set to 0.  as with most settings here,
;;  this will only affect newly-build pipelines.  it does not override settings at run time.
grid_enabled = 0

;; OPTIONAL
;; settings related to Sun Grid Engine

;; the root directory of the grid engine installation. the path to the
;;  various grid binaries and manpages depend on this location.
sge_root = /usr/local/packages/sge-root

;; the path to the qsub that should be used for submitted pipelines.  this will probably
;;  be under the sge_root defined above, but doesn't HAVE to be.  take care to not include an
;;  architecture-dependent full path if you have a heterogenous grid - instead, make a symlink
;;  somewhere like (/usr/local/bin/qsub) on all platforms and put that here.
sge_qsub = /usr/local/packages/sge-root/bin/lx24-x86/qsub

;; the cell in which the job runs. SGE Supports multiple grid configurations
;;  called cells. this setting specifies which cell to work with.
sge_cell = tigr

;; the port number used for communications with the grid master host.
;;  communications can be configured to run over TCP or UDP.
sge_qmaster_port = 536

;; the port number used for communications with the grid execution daemon
;;  on the execution hosts. Like communications with the master, connections
;;  with execution daemons can occur over TCP or UDP.
sge_execd_port = 537

;; The port number used for communications with the grid execution daemon
;;  on the execution hosts. Like communications with the master, connections
;;  with execution daemons can occur over TCP or UDP.
sge_arch = lx26-x86

;; Data placement support for local file storage on compute clouds
;; The location where the scripts from the vappio virtual applianace are installed (http://vappio.sf.net)
vappio_root = /opt/vappio_scripts
;; '1' - use data placement (local staging of inputs and remote harvesting of outputs)
;; '0' - do not use data placement 
;; When using data placment, vappio must be properly configured or jobs will fail to run 
;; Configuration options are stored in $vappio_root/vappio_config.sh
vappio_data_placement = 0


[authentication]
;; OPTIONAL
;; how do you want permissions to be handled in Ergatis?  here are the available options.
;; by default it's completely open, but you can also require user logins.  when open
;; ergatis executes pipelines as the user running the webserver.  
;; Note: If using one of these authentication methods, Authen::Simple must be installed
;; with the appropriate adaptor modules.
;;  options:
;;      open - logins not displayed. site completely open and anyone can run pipelines
;;             across all projects.
;;      kerberos - uses Kerberos to authenticate users.  this requires sudo privileges
;;             to be granted to the server user to sudo the 'RunWorkflow' or 'qsub RunWorkflow'
;;             commands as the user logged in
;;      ldap - uses ldap to authenticate.  Also requires sudo privileges as for Kerberos
;;      ldap - uses ldap with encryption to authenticate.  Also requires sudo privileges 
;;             as for Kerberos
;;      ad - uses ldap authentication, specifically using an ActiveDirectory host
authentication_method = open

;;  only do this one if you're doing kerberos authentication
kerberos_realm = AUTH.YOURSERVER.EDU

;;  only do these if you're using ldap authentication
;;      ldap_host:  can be a hostname, IP number or a URI.
;;      port:       default is 389
;;      basedn:     the distinguished name of the search base (not required for 
;;                  Active Directory LDAP)
ldap_host = ldap.place.org
ldap_port = 389
ldap_basedn = ou=users,dc=place,dc=org

;; this is only required if you're using 'ldap-tls' as your authentication method
ldap_tls_certificate = /etc/pki/tls/certs/ca-igs-bundle.crt

;; This is only necessary for ActiveDirectory hosts, which don't allow anonymous binding
ad_principal = place.org

;; If authentication is enabled this folder must be defined (and writable) as user session
;; metadata is written here and required when ergatis authentication is enabled. Ideally this folder
;; should be in an area that would not undergo any sort of periodic cleanup. An ideal location is the 
;; same folder that houses the global ID repository
session_db_dir = /opt/ergatis/global_id_repository

;; OPTIONAL
;; If this flag is enabled only the user who creates a pipeline can access/view it and any resources 
;; related to it (such as the config file, the detailed component view, the XML view). With this flag
;; enabled a user not authorized to view a pipeline will not be able to see pipelines they did not create 
;; in any of the pipeline list views and if they navigate to a pipeline they do not have access to they will be 
;; informed that they cannot view it.
per_account_pipeline_security = 0

;; If set, this requires a user to be logged in to create a pipeline.  The link on the interface
;; will change to say "new pipeline (login)" so that if a user clicks it they'll be redirected
;; to the login page before viewing the pipeline build page
require_login_for_pipeline_build = 0

;; this next setting will only be used if authentication_method is not 'none'.  if requiring
;;  authentication, do you want Ergatis to sudo as the authenticated user before starting
;;  the pipeline?  this will ensure that the files created during the pipeline run are owned
;;  by the logged in user.  if you set this the sysadmin will need to grant passwordless
;;  sudo rights for the webserver owner to all authenticated users for only the following 
;;  two commands (these are examples, modify your paths appropriately):
;;      
;;      /usr/local/packages/workflow/RunWorkflow
;;      /usr/local/bin/qsub /usr/local/packages/workflow/RunWorkflow 
;;
;;  here is an example sudo entry the sysadmin needs to create
;;
;;      apache         luthor=(ALL,!#0) NOPASSWD:/local/scratch/workflow/scripts/*.sh
;;
;; where you replace /local/scratch/workflow with the value you defined above for the
;;  workflow_run_dir variable.  You should take special care to ensure that this directory
;;  has 755 permissions so noone but the web server user can write to it.  Change 'apache'
;;  above to the user your web server is running as.  Also, you must comment out this line from
;;  the sudo config file:
;;
;;      #Defaults    requiretty
;;
;;
sudo_pipeline_execution = 0

[quick_links]

;; the interface will parse each key=value pair here and display these links at
;;  the top of any most pages.
code      = http://ergatis.svn.sourceforge.net/viewvc/ergatis/
bugs      = http://sourceforge.net/tracker/?atid=772583&group_id=148765&func=browse

[disabled_components]
;; if you want to hide any components from the interface simply put its name here
;;  and make its value equal a short explanation (may be displayed in some areas
;;  of the interface.  for example:
;;
;;  genemark = requires a paid license

[projects]

;; the interface will parse each key=value pair here to determine which
;;  project areas to show the user.  contained directly under each path
;;  should be the Workflow directory.
ecoli       = /usr/local/projects/ecoli
human       = /usr/local/projects/human
mouse       = /usr/local/projects/mouse
strep       = /usr/local/projects/strep
